{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resting State Complexity is Associated with Oral Ketamine Treatment Response: A Bayesian Analysis of Lempel-Ziv Complexity and Multi-Scale Entropy \n",
    "Authors: Mitchell J. S., Anijärv, T.E., Can, A., Dutton, M., Hermens, D.F., & Lagopoulos, J.\n",
    "\n",
    "Code created by Toomas Erik Anijärv and Jules Mitchell January 2024.\n",
    "\n",
    "You are free to use this or any other code from this repository for your own projects and publications. Citation or reference to the repository is not required, but would be much appreciated (see more on README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import mne, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import neurokit2 as nk\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Set and confirm default directory\n",
    "os.chdir('')\n",
    "os.getcwd()\n",
    "mne.set_log_level('error')\n",
    "\n",
    "# Import functions\n",
    "import signal_processing.pre_process as pre_process\n",
    "import basic.arrange_data as arrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set relevant folder paths\n",
    "raw_folder = 'Data\\Raw' # Folder where to get the raw EEG files\n",
    "# raw_folder = 'studies\\OKTOS'\n",
    "\n",
    "# Folder where to export the clean epochs files\n",
    "clean_folder = 'Data\\Clean'\n",
    "#clean_folder = 'studies\\OKTOS\\derivatives'\n",
    "\n",
    "# Folder to save the results\n",
    "results_folder = 'Data\\Results'\n",
    "#results_folder = 'studies\\OKTOS\\derivatives\\analysis'\n",
    "\n",
    "# Define timepoint sub-folders (i.e. edit if you don't want to run all timepoint)\n",
    "exp_folder = ['BAS', 'POST', 'FUP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEGLAB file epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EEG file information\n",
    "n_channels = 32\n",
    "sampling_freq = 250  # in Hertz\n",
    "info = mne.create_info(n_channels, sfreq=sampling_freq)\n",
    "\n",
    "# Loop over timepoint folders \n",
    "for exp in exp_folder:\n",
    "\n",
    "    # Get directories of raw EEG files and set export directory for clean files\n",
    "    dir_inprogress = os.path.join(raw_folder,exp)\n",
    "    print(dir_inprogress)\n",
    "    export_dir = os.path.join(clean_folder,exp)\n",
    "    file_dirs, subject_names = arrange.read_files(dir_inprogress,'.set')\n",
    "\n",
    "    # Loop through all the subjects' directories (EEG files directories)\n",
    "    for i in range(len(file_dirs)):\n",
    "        # Read in the raw EEG data\n",
    "        #data = loadmat(file_dirs[i])\n",
    "        #raw = mne.io.RawArray(file_dirs[i], info, first_samp=0, copy='auto', verbose=None)\n",
    "        raw = mne.io.read_raw_eeglab(file_dirs[i], eog=(), preload=False, uint16_codec=None, montage_units='mm', verbose=None)\n",
    "\n",
    "        epochs = mne.make_fixed_length_epochs(raw, duration=5.0, preload=False, reject_by_annotation=True, proj=True, overlap=0.0, id=1, verbose=None)\n",
    "\n",
    "        # Save epoched data\n",
    "        mne.Epochs.save(epochs, fname='{}/{}_clean-epo.fif'.format(export_dir,\n",
    "                                                                    subject_names[i]),\n",
    "                                                                    overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define arguments for each metric (LZC args provided if you wish to calculate permutation LZC also)\n",
    "lzc_args = dict(delay=1, dimension = 3, permutation = True)\n",
    "mse_args = dict(method=\"MSEn\", scale=20, dimension=2, tolerance='sd')\n",
    "\n",
    "# Define channels\n",
    "channels = [['Fp1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4',\n",
    "\t\t\t 'P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','Fp2','Fz','Cz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all experiments (i.e., timepoints)\n",
    "df = pd.DataFrame()\n",
    "for exp in exp_folder:\n",
    "    # Get directories of clean EEG files and set export directory\n",
    "    dir_inprogress = os.path.join(clean_folder,exp)\n",
    "    file_dirs, subject_names = arrange.read_files(dir_inprogress,'_clean-epo.fif')\n",
    "    print(subject_names)\n",
    "\n",
    "    # Doing it this way (based on the length of subject names) ensures the correct values are associated with each file\n",
    "    IDs = []\n",
    "    for s in subject_names:\n",
    "\t    IDs.append(s[0:6])\n",
    "     \n",
    "    Tx = []\n",
    "    for s in subject_names:\n",
    "        Tx.append(s[7:13])\n",
    "    \n",
    "    Task = []\n",
    "    for s in subject_names:\n",
    "        Task.append(s[14:16])\n",
    "\n",
    "    # Create dictionary to access response status based on ID\n",
    "    sample = [\n",
    "    'sub-01', 'sub-02', 'sub-03', 'sub-04', 'sub-05',\n",
    "    'sub-06', 'sub-07', 'sub-08', 'sub-09', 'sub-10',\n",
    "    'sub-11', 'sub-12', 'sub-13', 'sub-14', 'sub-15',\n",
    "    'sub-16', 'sub-17', 'sub-18', 'sub-19', 'sub-20',\n",
    "    'sub-21', 'sub-22', 'sub-23', 'sub-24', 'sub-25',\n",
    "    'sub-26', 'sub-27', 'sub-28', 'sub-29', 'sub-31',\n",
    "    'sub-32', 'sub-33', 'sub-34', 'sub-35', 'sub-36',\n",
    "    'sub-38', 'sub-39', 'sub-40']\n",
    "\n",
    "    resp_status = [1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]\n",
    "\n",
    "    # Create a dictionary with participant IDs as keys and response statuses as values\n",
    "    response_dict = dict(zip(sample, resp_status))\n",
    "\t\n",
    "    # Loop through all the subjects' directories (EEG files directories)\n",
    "    df_exp = pd.DataFrame(index=range(len(file_dirs)))\n",
    "    df_exp_channels = pd.DataFrame(index=range(len(file_dirs)), columns = channels)\n",
    "    df_exp_channels_perm = pd.DataFrame(index=range(len(file_dirs)), columns = channels)\n",
    "\n",
    "    for i in range(len(file_dirs)):\n",
    "        # Update df_exp and df_exp_channels with timepoint (Tx) and Task (e.g. Eyes closed(EC))\n",
    "        df_exp.loc[i, 'Subject'] = IDs[i]\n",
    "        df_exp.loc[i, 'Timepoint'] = Tx[i]\n",
    "        df_exp.loc[i, 'Task'] = Task[i]\n",
    "        df_exp.loc[i, 'Responder'] = response_dict[IDs[i]]\n",
    "        \n",
    "        df_exp_channels.loc[i, 'Subject'] = IDs[i]\n",
    "        df_exp_channels.loc[i, 'Timepoint'] = Tx[i]\n",
    "        df_exp_channels.loc[i, 'Task'] = Task[i]\n",
    "        df_exp_channels.loc[i, 'Responder'] = response_dict[IDs[i]]\n",
    "\n",
    "        df_exp_channels_perm.loc[i, 'Subject'] = IDs[i]\n",
    "        df_exp_channels_perm.loc[i, 'Timepoint'] = Tx[i]\n",
    "        df_exp_channels_perm.loc[i, 'Task'] = Task[i]\n",
    "        df_exp_channels_perm.loc[i, 'Responder'] = response_dict[IDs[i]]\n",
    "\n",
    "        # Read the clean data from the disk\n",
    "        print('{}: {} ({}/{})'.format(exp, subject_names[i], i+1, len(file_dirs)))\n",
    "        epochs = mne.read_epochs(fname='{}/{}_clean-epo.fif'.format(dir_inprogress, subject_names[i]),\n",
    "                                                                    verbose=False)\n",
    "        \n",
    "        # Convert data file to dataframe \n",
    "        df_epochs = epochs.to_data_frame()\n",
    "        \n",
    "        ### Lempel-Ziv complexity\n",
    "        # Go through all the channels signals\n",
    "        lzc_i = []\n",
    "        lzc_med_i = []\n",
    "        lzc_perm = []\n",
    "        for ch in epochs.info['ch_names']:\n",
    "            print(ch)\n",
    "            # Go through all epochs in the current channel signal\n",
    "            lzc_ch = []\n",
    "            lzc_ch_med = []\n",
    "            lzc_ch_perm = []\n",
    "            for epo in df_epochs['epoch'].unique():\n",
    "                # Calculate Lempel-Ziv Complexity (LZC) for the current epoch\n",
    "                epo_signal = df_epochs[df_epochs['epoch']==epo][ch]\n",
    "                # Normal (mean)\n",
    "                lzc_epo, info_1 = nk.complexity_lempelziv(epo_signal, symbolize='mean', permutation = False)\n",
    "                lzc_ch.append(lzc_epo)\n",
    "                # Normal (median)\n",
    "                lzc_epo_med, info_2 = nk.complexity_lempelziv(epo_signal, symbolize='median', permutation = False)\n",
    "                lzc_ch_med.append(lzc_epo)\n",
    "                # Permutation\n",
    "                lzc_epo_perm, info_3 = nk.complexity_lempelziv(epo_signal, **lzc_args)\n",
    "                lzc_ch_perm.append(lzc_epo_perm)\n",
    "                \n",
    "            # Average all epochs' LZC values to get a single value for the channel & add to list\n",
    "            lzc_i.append(np.mean(lzc_ch))\n",
    "            lzc_med_i.append(np.mean(lzc_ch_med))\n",
    "            lzc_perm.append(np.mean(lzc_ch_perm))\n",
    "\n",
    "            # Add channel complexity values to dataframe\n",
    "            df_exp_channels.loc[i, ch] = np.mean(lzc_ch)\n",
    "            df_exp_channels_perm.loc[i, ch] = np.mean(lzc_ch_perm)\n",
    "\n",
    "        # Average all the channels' LZC values to get a single value for the subject & add to master dataframe\n",
    "        lzc_i_mean = np.mean(lzc_i)\n",
    "        lzc_med_i_mean = np.mean(lzc_med_i)\n",
    "        lzc_perm_mean = np.mean(lzc_perm)\n",
    "        df_exp.loc[i, 'LZC'] = lzc_i_mean\n",
    "        df_exp.loc[i, 'LZC_M'] = lzc_med_i_mean\n",
    "        df_exp.loc[i, 'LZC_P'] = lzc_perm_mean\n",
    "\n",
    "        ### Multiscale Sample Entropy\n",
    "        # Go through all the channels signals\n",
    "        mse_i = []\n",
    "        mse_vals_i = np.zeros(shape=(len(epochs.info['ch_names']), mse_args['scale']))\n",
    "\n",
    "        for c, ch in enumerate(epochs.info['ch_names']):\n",
    "            # Go through all epochs in the current channel signal\n",
    "            mse_ch = []\n",
    "            mse_vals_epo = []\n",
    "\n",
    "            for epo in df_epochs['epoch'].unique():\n",
    "                # Calculate Multiscale Sample Entropy (MSE) measures for the current epoch\n",
    "                epo_signal = df_epochs[df_epochs['epoch']==epo][ch]\n",
    "                mse_epo, info_3 = nk.entropy_multiscale(epo_signal.to_numpy(), **mse_args)\n",
    "\n",
    "                # Get the total and scales' MSE values for the current epoch & add to list including all epochs\n",
    "                mse_ch.append(mse_epo)\n",
    "                mse_vals_epo.append(info_3.get('Value'))\n",
    "\n",
    "            # Average all epochs' MSE values for every channel for the subject\n",
    "            mse_vals_i[c] = np.mean(mse_vals_epo, axis=0)\n",
    "\n",
    "            # Average all epochs' MSE totals to get a single value for the channel & add to list\n",
    "            mse_i.append(np.mean(mse_ch))\n",
    "\n",
    "        # Average all the channels' MSE and MSPLZC totals & values to get global value\n",
    "        mse_i_mean = np.mean(mse_i)\n",
    "        mse_vals_i_mean = np.mean(mse_vals_i, axis=0)\n",
    "        \n",
    "        # Add total MSE to dataframe for the subject\n",
    "        df_exp.loc[i, 'MSE (total)'] = mse_i_mean\n",
    "\n",
    "        # Add all scales' MSE values to dataframe for the subject\n",
    "        for scl in range(mse_args['scale']):\n",
    "            df_exp.loc[i, 'MSE (scale={})'.format(scl+1)] = mse_vals_i_mean[scl]\n",
    "        \n",
    "    # Add the current timepoint data to the master dataframe\n",
    "    df = pd.concat([df, df_exp])\n",
    "\n",
    "df.to_excel('{}/Complexity_results.xlsx'.format(results_folder))\n",
    "df_exp_channels.to_excel('{}/LZC_chan_results.xlsx'.format(results_folder))\n",
    "df_exp_channels_perm.to_excel('{}/LZC_perm_chan_results.xlsx'.format(results_folder))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('EEG-pipeline-TI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a57757abf3656da35bfbc8305ac62bd00e5fa58b0b8fef7bd72ac98b35a77f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
